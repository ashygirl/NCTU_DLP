{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import read_bci_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self,activation=nn.ELU()):\n",
    "        super(EEGNet,self).__init__()\n",
    "        self.firstconv=nn.Sequential(\n",
    "            nn.Conv2d(1,16,kernel_size=(1,51),stride=(1,1),padding=(0,25),bias=False),\n",
    "            nn.BatchNorm2d(16,eps=1e-5,momentum=0.1,affine=True,track_running_stats=True)\n",
    "        )\n",
    "        self.depthwiseConv=nn.Sequential(\n",
    "            nn.Conv2d(16,32,kernel_size=(2,1),stride=(1,1),groups=16,bias=False),\n",
    "            nn.BatchNorm2d(32,eps=1e-5,momentum=0.1,affine=True,track_running_stats=True),\n",
    "            activation,\n",
    "            nn.AvgPool2d(kernel_size=(1,4),stride=(1,4),padding=0),\n",
    "            nn.Dropout(p=0.25)\n",
    "        )\n",
    "        self.seperableConv=nn.Sequential(\n",
    "            nn.Conv2d(32,32,kernel_size=(1,15),stride=(1,1),padding=(0,7),bias=False),\n",
    "            nn.BatchNorm2d(32,eps=1e-5,momentum=0.1,affine=True,track_running_stats=True),\n",
    "            activation,\n",
    "            nn.AvgPool2d(kernel_size=(1,8),stride=(1,8),padding=0),\n",
    "            nn.Dropout(p=0.25)\n",
    "        )\n",
    "        self.classify=nn.Linear(736,2)\n",
    "    def forward(self,X):\n",
    "        out=self.firstconv(X)\n",
    "        out=self.depthwiseConv(out)\n",
    "        out=self.seperableConv(out)\n",
    "        out=out.view(out.shape[0],-1)\n",
    "        out=self.classify(out)\n",
    "        return out\n",
    "\n",
    "class DeepConvNet(nn.Module):\n",
    "    def __init__(self,activation=nn.ELU()):\n",
    "        super(DeepConvNet,self).__init__()\n",
    "        self.conv0=nn.Conv2d(1,25,kernel_size=(1,5))\n",
    "        channels=[25,25,50,100,200]\n",
    "        kernel_sizes=[None,(2,1),(1,5),(1,5),(1,5)]\n",
    "        for i in range(1,len(channels)):\n",
    "            setattr(self,'conv'+str(i),nn.Sequential(\n",
    "                nn.Conv2d(channels[i-1],channels[i],kernel_size=kernel_sizes[i]),\n",
    "                nn.BatchNorm2d(channels[i],eps=1e-5,momentum=0.1),\n",
    "                activation,\n",
    "                nn.MaxPool2d(kernel_size=(1,2)),\n",
    "                nn.Dropout(p=0.5)\n",
    "            ))\n",
    "        self.classify=nn.Linear(8600,2)\n",
    "    def forward(self,X):\n",
    "        out=self.conv0(X)\n",
    "        out=self.conv1(out)\n",
    "        out=self.conv2(out)\n",
    "        out=self.conv3(out)\n",
    "        out=self.conv4(out)\n",
    "        out=out.view(out.shape[0],-1)\n",
    "        neurons=out.shape[0]\n",
    "        out=self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,loader_test,device):\n",
    "    model.eval()\n",
    "    correct=0\n",
    "    for idx,(data,target) in enumerate(loader_test):\n",
    "        data=data.to(device,dtype=torch.float)\n",
    "        target=target.to(device,dtype=torch.long)\n",
    "        predict=model(data)\n",
    "        correct+=predict.max(dim=1)[1].eq(target).sum().item()\n",
    "    \n",
    "    correct=100.*correct/len(loader_test.dataset)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EEGNet(\n",
       "  (firstconv): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(1, 51), stride=(1, 1), padding=(0, 25), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (depthwiseConv): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(2, 1), stride=(1, 1), groups=16, bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
       "    (4): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (seperableConv): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 15), stride=(1, 1), padding=(0, 7), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
       "    (4): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (classify): Linear(in_features=736, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=EEGNet(nn.LeakyReLU())\n",
    "model.load_state_dict(torch.load(os.path.join('eeg models','ReLU.pt')))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1, 2, 750) (1080,) (1080, 1, 2, 750) (1080,)\n",
      "test dataset:\n",
      "(tensor([[[[ -8.3359,  -8.7829,  -9.3748,  ...,  -2.1328,  -2.8224,  -2.0885],\n",
      "          [-10.6524,  -8.4476,  -5.9331,  ...,   0.5607,  -4.1266,  -8.1379]]],\n",
      "\n",
      "\n",
      "        [[[ -1.6904,  -3.2816,  -3.6523,  ...,   4.0093,   0.7018,   0.7155],\n",
      "          [  3.4033,   2.0698,  -1.6959,  ...,   7.7458,   3.5498,   3.7207]]],\n",
      "\n",
      "\n",
      "        [[[ -2.6835,  -0.4836,   1.9848,  ...,  -3.9513,   0.4729,   5.2923],\n",
      "          [  2.6602,   3.9587,   4.9871,  ...,  -0.6675,  -0.2266,   0.0633]]]],\n",
      "       dtype=torch.float64), tensor([1., 0., 1.], dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "_,_,X_test,y_test=read_bci_data()\n",
    "dataset=TensorDataset(torch.from_numpy(X_test),torch.from_numpy(y_test))\n",
    "loader_test=DataLoader(dataset,batch_size=256,shuffle=False,num_workers=4)\n",
    "print(f'test dataset:\\n{dataset[:3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.24%\n"
     ]
    }
   ],
   "source": [
    "acc=evaluate(model,loader_test,device)\n",
    "print(f'accuracy: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
