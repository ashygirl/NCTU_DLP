{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watch model acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self,num_class,pretrained=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_class: #target class\n",
    "            pretrained: \n",
    "                True: the model will have pretrained weights, and only the last layer's 'requires_grad' is True(trainable)\n",
    "                False: random initialize weights, and all layer's 'require_grad' is True\n",
    "        \"\"\"\n",
    "        super(ResNet18,self).__init__()\n",
    "        self.model=models.resnet18(pretrained=pretrained)\n",
    "        if pretrained:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad=False\n",
    "        num_neurons=self.model.fc.in_features\n",
    "        self.model.fc=nn.Linear(num_neurons,num_class)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        out=self.model(X)\n",
    "        return out\n",
    "    \n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self,num_class,pretrained=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_class: #target class\n",
    "            pretrained: \n",
    "                True: the model will have pretrained weights, and only the last layer's 'requires_grad' is True(trainable)\n",
    "                False: random initialize weights, and all layer's 'require_grad' is True\n",
    "        \"\"\"\n",
    "        super(ResNet50,self).__init__()\n",
    "        self.model=models.resnet50(pretrained=pretrained)\n",
    "        if pretrained:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad=False\n",
    "        num_neurons=self.model.fc.in_features\n",
    "        self.model.fc=nn.Linear(num_neurons,num_class)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        out=self.model(X)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,loader_test,device,num_class):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: resnet model\n",
    "        loader_test: testing dataloader\n",
    "        device: gpu/cpu\n",
    "        num_class: #target class\n",
    "    Returns:\n",
    "        confusion_matrix: (num_class,num_class) ndarray\n",
    "        acc: accuracy rate\n",
    "    \"\"\"\n",
    "    confusion_matrix=np.zeros((num_class,num_class))\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        model.eval()\n",
    "        correct=0\n",
    "        for images,targets in loader_test:  \n",
    "            images,targets=images.to(device),targets.to(device,dtype=torch.long)\n",
    "            predict=model(images)\n",
    "            predict_class=predict.max(dim=1)[1]\n",
    "            correct+=predict_class.eq(targets).sum().item()\n",
    "            for i in range(len(targets)):\n",
    "                confusion_matrix[int(targets[i])][int(predict_class[i])]+=1\n",
    "        acc=100.*correct/len(loader_test.dataset)\n",
    "        \n",
    "    # normalize confusion_matrix\n",
    "    confusion_matrix=confusion_matrix/confusion_matrix.sum(axis=1).reshape(num_class,1)\n",
    "    \n",
    "    return confusion_matrix,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDataSet(Dataset):\n",
    "    def __init__(self, img_path, mode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_path: Root path of the dataset.\n",
    "            mode: training/testing\n",
    "            \n",
    "            self.img_names (string list): String list that store all image names.\n",
    "            self.labels (int or float list): Numerical list that store all ground truth label values.\n",
    "        \"\"\"\n",
    "        self.img_path = img_path\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.img_names=np.squeeze(pd.read_csv('train_img.csv' if mode=='train' else 'test_img.csv').values)\n",
    "        self.labels=np.squeeze(pd.read_csv('train_label.csv' if mode=='train' else 'test_label.csv').values)\n",
    "        assert len(self.img_names)==len(self.labels),'length not the same'\n",
    "        self.data_len=len(self.img_names)\n",
    "        \n",
    "        self.transformations=transforms.Compose([transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.3749,0.2602,0.1857),(0.2526, 0.1780, 0.1291))])\n",
    "        print(f'>> Found {self.data_len} images...')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_img_name=os.path.join(self.img_path,self.img_names[index]+'.jpeg')\n",
    "        single_img=Image.open(single_img_name)  # read an PIL image\n",
    "        img=self.transformations(single_img)\n",
    "        label=self.labels[index]\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Found 7025 images...\n"
     ]
    }
   ],
   "source": [
    "dataset_test=RetinopathyDataSet(img_path='data',mode='test')\n",
    "loader_test=DataLoader(dataset=dataset_test,batch_size=8,shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model=ResNet50(num_class=5,pretrained=True)\n",
    "model.load_state_dict(torch.load(os.path.join('models','resnet50_with_pretraining.pt')))\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.74733096085409\n"
     ]
    }
   ],
   "source": [
    "_,acc=evaluate(model,loader_test,device,num_class=5)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
