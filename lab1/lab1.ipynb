{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01\n",
    "reference: https://www.youtube.com/watch?v=-yhm3WdGFok  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\" Sigmoid function.\n",
    "    This function accepts any shape of np.ndarray object as input and perform sigmoid operation.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def der_sigmoid(y):\n",
    "    \"\"\" First derivative of Sigmoid function.\n",
    "    The input to this function should be the value that output from sigmoid function.\n",
    "    \"\"\"\n",
    "    return y * (1 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenData:\n",
    "    @staticmethod\n",
    "    def _gen_linear(n=100):\n",
    "        \"\"\" Data generation (Linear)\n",
    "\n",
    "        Args:\n",
    "            n (int):    the number of data points generated in total.\n",
    "\n",
    "        Returns:\n",
    "            data (np.ndarray, np.float):    the generated data with shape (n, 2). Each row represents\n",
    "                a data point in 2d space.\n",
    "            labels (np.ndarray, np.int):    the labels that correspond to the data with shape (n, 1).\n",
    "                Each row represents a corresponding label (0 or 1).\n",
    "        \"\"\"\n",
    "        data = np.random.uniform(0, 1, (n, 2))\n",
    "\n",
    "        inputs = []\n",
    "        labels = []\n",
    "\n",
    "        for point in data:\n",
    "            inputs.append([point[0], point[1]])\n",
    "\n",
    "            if point[0] > point[1]:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "        return np.array(inputs), np.array(labels).reshape((-1, 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _gen_xor(n=100):\n",
    "        \"\"\" Data generation (XOR)\n",
    "\n",
    "        Args:\n",
    "            n (int):    the number of data points generated in total.\n",
    "\n",
    "        Returns:\n",
    "            data (np.ndarray, np.float):    the generated data with shape (n, 2). Each row represents\n",
    "                a data point in 2d space.\n",
    "            labels (np.ndarray, np.int):    the labels that correspond to the data with shape (n, 1).\n",
    "                Each row represents a corresponding label (0 or 1).\n",
    "        \"\"\"\n",
    "        data_x = np.linspace(0, 1, n // 2)\n",
    "\n",
    "        inputs = []\n",
    "        labels = []\n",
    "\n",
    "        for x in data_x:\n",
    "            inputs.append([x, x])\n",
    "            labels.append(0)\n",
    "\n",
    "            if x == 1 - x:\n",
    "                continue\n",
    "\n",
    "            inputs.append([x, 1 - x])\n",
    "            labels.append(1)\n",
    "\n",
    "        return np.array(inputs), np.array(labels).reshape((-1, 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_data(mode, n):\n",
    "        \"\"\" Data gather interface\n",
    "\n",
    "        Args:\n",
    "            mode (str): 'Linear' or 'XOR', indicate which generator is used.\n",
    "            n (int):    the number of data points generated in total.\n",
    "        \"\"\"\n",
    "        assert mode == 'Linear' or mode == 'XOR'\n",
    "\n",
    "        data_gen_func = {\n",
    "            'Linear': GenData._gen_linear,\n",
    "            'XOR': GenData._gen_xor\n",
    "        }[mode]\n",
    "\n",
    "        return data_gen_func(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe\n",
    "![nn](nn.png)  \n",
    "\n",
    "![computational graph](computationalgraph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-69d67ecf91b4>, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-69d67ecf91b4>\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    grad_C_y=-(gt_y/(pred_y+)+)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class SimpleNet:\n",
    "    EPS=1e-9\n",
    "    \n",
    "    def __init__(self, hidden_size, num_step=2000, print_interval=100):\n",
    "        \"\"\" A hand-crafted implementation of simple network.\n",
    "\n",
    "        Args:\n",
    "            hidden_size:    a tuple(z1,z2) of the number of hidden neurons used in each of the two layer.\n",
    "            num_step (optional):    the total number of training steps.\n",
    "            print_interval (optional):  the number of steps between each reported number.\n",
    "        \"\"\"\n",
    "        self.num_step = num_step\n",
    "        self.print_interval = print_interval\n",
    "\n",
    "        # Model parameters initialization\n",
    "        # Please initiate your network parameters here.\n",
    "        '''\n",
    "        X-> W1-> z1-> a1-> W2-> z2-> a2-> W3-> z3-> a3==y\n",
    "        '''\n",
    "        self.X=np.zeros((2,1))\n",
    "        self.W=[np.random.rand(hidden_size[0],2),np.random.rand(hidden_size[1],hidden_size[0]),np.random.rand(1,hidden_size[1])]\n",
    "        self.z=[np.zeros((hidden_size[0],1)),np.zeros((hidden_size[1],1)),np.zeros((1,1))]\n",
    "        self.a=[np.zeros((hidden_size[0],1)),np.zeros((hidden_size[1],1)),np.zeros((1,1))]\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Implementation of the forward pass.\n",
    "        It should accepts the inputs and passing them through the network and return results.\n",
    "        \"\"\"\n",
    "        self.X=inputs\n",
    "        self.z[0]=self.W[0]@self.X\n",
    "        self.a[0]=sigmoid(self.z[0])\n",
    "        self.z[1]=self.W[1]@self.a[0]\n",
    "        self.a[1]=sigmoid(self.z[1])\n",
    "        self.z[2]=self.W[2]@self.a[1]\n",
    "        self.a[2]=sigmoid(self.z[2])\n",
    "\n",
    "        return self.a[2]  #self.output==self.a[2]\n",
    "\n",
    "    def backward(self,gt_y,pred_y):\n",
    "        \"\"\" Implementation of the backward pass.\n",
    "        It should utilize the saved loss to compute gradients and update the network all the way to the front.\n",
    "        \n",
    "        Args:\n",
    "            gt_y: an (1*1) ndarray\n",
    "            pred_y: an (1*1) ndarray\n",
    "        \"\"\"\n",
    "        Cost=-(gt_y*math.log(pred_y)+(1-gt_y)*math.log(1-pred_y))\n",
    "        grad_C_y=-(gt_y/(pred_y+EPS)-(1-gt_y)/(1-pred_y))\n",
    "        \n",
    "        \n",
    "\n",
    "    def train(self, inputs, labels):\n",
    "        \"\"\" The training routine that runs and update the model.\n",
    "\n",
    "        Args:\n",
    "            inputs: the training (and testing) data used in the model.\n",
    "            labels: the ground truth of correspond to input data.\n",
    "        \"\"\"\n",
    "        # make sure that the amount of data and label is match\n",
    "        assert inputs.shape[0] == labels.shape[0]\n",
    "\n",
    "        n = inputs.shape[0]\n",
    "\n",
    "        for epochs in range(self.num_step):\n",
    "            for idx in range(n):\n",
    "                # operation in each training step:\n",
    "                #   1. forward passing\n",
    "                #   2. compute loss\n",
    "                #   3. propagate gradient backward to the front\n",
    "                self.output = self.forward(inputs[idx:idx+1, :])\n",
    "                self.error = self.output - labels[idx:idx+1, :]\n",
    "                self.backward(labels[idx:idx+1,:],self.output)\n",
    "\n",
    "            if epochs % self.print_interval == 0:\n",
    "                print('Epochs {}: '.format(epochs))\n",
    "                self.test(inputs, labels)\n",
    "\n",
    "        print('Training finished')\n",
    "        self.test(inputs, labels)\n",
    "\n",
    "    def test(self, inputs, labels):\n",
    "        \"\"\" The testing routine that run forward pass and report the accuracy.\n",
    "\n",
    "        Args:\n",
    "            inputs: the testing data. One or several data samples are both okay.\n",
    "                The shape is expected to be [BatchSize, 2].\n",
    "            labels: the ground truth correspond to the inputs.\n",
    "        \"\"\"\n",
    "        n = inputs.shape[0]\n",
    "\n",
    "        error = 0.0\n",
    "        for idx in range(n):\n",
    "            result = self.forward(inputs[idx:dix+1, :])\n",
    "            error += abs(result - labels[idx:idx+1, :])\n",
    "\n",
    "        error /= n\n",
    "        print('accuracy: %.2f' % ((1 - error)*100) + '%')\n",
    "        print('')\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_result(data, gt_y, pred_y):\n",
    "        \"\"\" Data visualization with ground truth and predicted data comparison. There are two plots\n",
    "        for them and each of them use different colors to differentiate the data with different labels.\n",
    "\n",
    "        Args:\n",
    "            data:   the input data\n",
    "            gt_y:   ground truth to the data\n",
    "            pred_y: predicted results to the data\n",
    "        \"\"\"\n",
    "        assert data.shape[0] == gt_y.shape[0]\n",
    "        assert data.shape[0] == pred_y.shape[0]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title('Ground Truth', fontsize=18)\n",
    "\n",
    "        for idx in range(data.shape[0]):\n",
    "            if gt_y[idx] == 0:\n",
    "                plt.plot(data[idx][0], data[idx][1], 'ro')\n",
    "            else:\n",
    "                plt.plot(data[idx][0], data[idx][1], 'bo')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title('Prediction', fontsize=18)\n",
    "\n",
    "        for idx in range(data.shape[0]):\n",
    "            if pred_y[idx] == 0:\n",
    "                plt.plot(data[idx][0], data[idx][1], 'ro')\n",
    "            else:\n",
    "                plt.plot(data[idx][0], data[idx][1], 'bo')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88675531 0.59938117 0.78700302]]\n"
     ]
    }
   ],
   "source": [
    "a=np.random.rand(3,3)\n",
    "a=a[2:3,:]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
